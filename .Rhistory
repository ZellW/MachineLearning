mutate(selected_node = ifelse(is.na(selected_node), 1, 2)) %>%
activate(edges) %>%
mutate(selected_edge = ifelse(is.na(selected_edge), 1, 2)) %>%
arrange(selected_edge)
shortest
shortest %>%
ggraph(layout = "kk") +
geom_edge_diagonal(aes(alpha = selected_edge), color = "gray") +
geom_node_text(aes(label = label, color =name, alpha = selected_node ), size = 3)
shortest %>%
activate(edges) %>%
filter(selected_edge == 2) %>%
as_tibble() %>%
summarise(
total_stops = n() - 1,
total_time = round(sum(journey_time) / 60))
from <- which(stations == "Montpellier")
to <-  which(stations == "Laval")
shortest <- graph_routes %>%
morph(to_shortest_path, from, to, weights = journey_time) %>%
mutate(selected_node = TRUE) %>%
activate(edges) %>%
mutate(selected_edge = TRUE) %>%
unmorph() %>%
activate(nodes) %>%
mutate(selected_node = ifelse(is.na(selected_node), 1, 2)) %>%
activate(edges) %>%
mutate(selected_edge = ifelse(is.na(selected_edge), 1, 2)) %>%
arrange(selected_edge)
shortest %>%
ggraph(layout = "kk") +
geom_edge_diagonal(aes(alpha = selected_edge), color = "gray") +
geom_node_text(aes(label = label, color =name, alpha = selected_node ), size = 3)
Additional, the same code can be recycled to obtain the trip summarized data.
from <- which(stations == "Montpellier")
to <-  which(stations == "Laval")
shortest <- graph_routes %>%
morph(to_shortest_path, from, to, weights = journey_time) %>%
mutate(selected_node = TRUE) %>%
activate(edges) %>%
mutate(selected_edge = TRUE) %>%
unmorph() %>%
activate(nodes) %>%
mutate(selected_node = ifelse(is.na(selected_node), 1, 2)) %>%
activate(edges) %>%
mutate(selected_edge = ifelse(is.na(selected_edge), 1, 2)) %>%
arrange(selected_edge)
shortest %>%
ggraph(layout = "kk") +
geom_edge_diagonal(aes(alpha = selected_edge), color = "gray") +
geom_node_text(aes(label = label, color =name, alpha = selected_node ), size = 3)
shortest %>%
activate(edges) %>%
filter(selected_edge == 2) %>%
as_tibble() %>%
summarise(
total_stops = n() - 1,
total_time = round(sum(journey_time) / 60)
)
knitr::opts_knit$set(
root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/Deep_Learning_with_R')
#remotes::install_github("rstudio/gt")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", "gt", "here", "stringr", prompt = TRUE)
setwd("~/GitHub/DeepLearning/Deep_Learning_with_R")
knitr::opts_knit$set(
root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/Deep_Learning_with_R')
img_shape <- c(28, 28, 1)
batch_size <- 16
latent_dim <- 2L # Dimensionality of the latent space: a 2D plane
input_img <- layer_input(shape = img_shape)
library(keras)
img_shape <- c(28, 28, 1)
batch_size <- 16
latent_dim <- 2L # Dimensionality of the latent space: a 2D plane
input_img <- layer_input(shape = img_shape)
x <- input_img %>% layer_conv_2d(filters = 32, kernel_size = 3, padding = "same", activation = "relu") %>%
layer_conv_2d(filters = 64, kernel_size = 3, padding = "same", activation = "relu", strides = c(2, 2)) %>%
layer_conv_2d(filters = 64, kernel_size = 3, padding = "same", activation = "relu") %>%
layer_conv_2d(filters = 64, kernel_size = 3, padding = "same", activation = "relu")
shape_before_flattening <- k_int_shape(x)
x <- x %>% layer_flatten() %>% layer_dense(units = 32, activation = "relu")
z_mean <- x %>% layer_dense(units = latent_dim)    # The input image ends upbeing encoded into these two parameters.
z_log_var <- x %>% layer_dense(units = latent_dim)
sampling <- function(args) {
c(z_mean, z_log_var) %<-% args
epsilon <- k_random_normal(shape = list(k_shape(z_mean)[1], latent_dim), mean = 0, stddev = 1)
z_mean + k_exp(z_log_var) * epsilon}
z <- list(z_mean, z_log_var) %>% layer_lambda(sampling)
decoder_input <- layer_input(k_int_shape(z)[-1])
# Input where you’ll feed z
x <- decoder_input %>%
# Upsamples the input
layer_dense(units = prod(as.integer(shape_before_flattening[-1])), activation = "relu") %>%
# Reshapes z into a feature map of the same shape as the feature map just before the last layer_flatten in the encoder model
# Uses a layer_conv_2d_transpose and layer_conv_2d to decode z into a feature map the same size as the original image input
layer_reshape(target_shape = shape_before_flattening[-1]) %>%
layer_conv_2d_transpose(filters = 32, kernel_size = 3, padding = "same", activation = "relu", strides = c(2, 2)) %>%
# You end up with a feature map the same size as the original input.
layer_conv_2d(filters = 1, kernel_size = 3, padding = "same", activation = "sigmoid")
decoder <- keras_model(decoder_input, x) # Instantiates the decoder model,which turns “decoder_input” into the decoded image
z_decoded <- decoder(z)
library(R6)
CustomVariationalLayer <- R6Class("CustomVariationalLayer", inherit = KerasLayer, public = list(
vae_loss = function(x, z_decoded) {
x <- k_flatten(x)
z_decoded <- k_flatten(z_decoded)
xent_loss <- metric_binary_crossentropy(x, z_decoded)
kl_loss <- -5e-4 * k_mean(1 + z_log_var - k_square(z_mean) - k_exp(z_log_var),axis = -1L)
k_mean(xent_loss + kl_loss)},
# Custom layers are implemented by writing a “call” method.
call = function(inputs, mask = NULL) {
x <- inputs[[1]]
z_decoded <- inputs[[2]]
loss <- self$vae_loss(x, z_decoded)
self$add_loss(loss, inputs = inputs)
x} # You don’t use this output, but the layer must return something.
)
# Wraps the R6 class in a standard Keras layer function
layer_variational <- function(object) {create_layer(CustomVariationalLayer, object, list())}
# Calls the custom layer on the input and the decoded output to obtain the final model output
y <- list(input_img, z_decoded) %>% layer_variational()
vae <- keras_model(input_img, y)
vae %>% compile(optimizer = "rmsprop", loss = NULL)
mnist <- dataset_mnist()
c(c(x_train, y_train), c(x_test, y_test)) %<-% mnist
x_train <- x_train / 255
x_train <- array_reshape(x_train, dim =c(dim(x_train), 1))
x_test <- x_test / 255
x_test <- array_reshape(x_test, dim =c(dim(x_test), 1))
vae %>% fit(x = x_train, y = NULL, epochs = 10, batch_size = batch_size, validation_data = list(x_test, NULL))
save.image("VAE.RData")
# You’ll display a grid of 15 × 15 digits (255 digits in total).
n <- 15
digit_size <- 28
# Transforms linearly spaced coordinates using the qnorm function to produce values of the latent variable z (because the prior of the latent space is Gaussian)
grid_x <- qnorm(seq(0.05, 0.95, length.out = n))
grid_y <- qnorm(seq(0.05, 0.95, length.out = n))
op <- par(mfrow = c(n, n), mar = c(0,0,0,0), bg = "black")
for (i in 1:length(grid_x)) {
yi <- grid_x[[i]]
for (j in 1:length(grid_y)) {
xi <- grid_y[[j]]
z_sample <- matrix(c(xi, yi), nrow = 1, ncol = 2)
# Repeats z multiple times to form a complete batch
z_sample <- t(replicate(batch_size, z_sample, simplify = "matrix"))
x_decoded <- decoder %>% predict(z_sample, batch_size = batch_size)
# Reshapes the first digit in the batch from 28 × 28 × 1 to 28 × 28
digit <- array_reshape(x_decoded[1,,,], dim = c(digit_size, digit_size))
plot(as.raster(digit))
}
par(op)
plot(as.raster(im))
image
im <- deprocess_image(image)
plot(as.raster(im))}
plot(as.raster(im))
im <- deprocess_image(image)
preprocess_image <- function(path) {
img <- image_load(path, target_size = c(img_nrows, img_ncols)) %>%
image_to_array() %>%
array_reshape(c(1, dim(.)))
imagenet_preprocess_input(img)}
deprocess_image <- function(x) {
# Zero-centers by removing the mean pixel value from ImageNet. This reverses a transformation done by imagenet_preprocess_input
x <- x[1,,,]
x[,,1] <- x[,,1] + 103.939
x[,,2] <- x[,,2] + 116.779
x[,,3] <- x[,,3] + 123.68
# Converts images from ‘BGR’ to ‘RGB’. This is also part of the reversal of imagenet_preprocess_input.
x <- x[,,c(3,2,1)]
x[x > 255] <- 255
x[x < 0] <- 0
x[] <- as.integer(x)/255
x}
im <- deprocess_image(image)
# You’ll display a grid of 15 × 15 digits (255 digits in total).
n <- 15
digit_size <- 28
# Transforms linearly spaced coordinates using the qnorm function to produce values of the latent variable z (because the prior of the latent space is Gaussian)
grid_x <- qnorm(seq(0.05, 0.95, length.out = n))
grid_y <- qnorm(seq(0.05, 0.95, length.out = n))
op <- par(mfrow = c(n, n), mar = c(0,0,0,0), bg = "black")
for (i in 1:length(grid_x)) {
yi <- grid_x[[i]]
for (j in 1:length(grid_y)) {
xi <- grid_y[[j]]
z_sample <- matrix(c(xi, yi), nrow = 1, ncol = 2)
# Repeats z multiple times to form a complete batch
z_sample <- t(replicate(batch_size, z_sample, simplify = "matrix"))
x_decoded <- decoder %>% predict(z_sample, batch_size = batch_size)
# Reshapes the first digit in the batch from 28 × 28 × 1 to 28 × 28
digit <- array_reshape(x_decoded[1,,,], dim = c(digit_size, digit_size))
plot(as.raster(digit))
}
par(op)
op <- par(mfrow = c(n, n), mar = c(0,0,0,0), bg = "black")
library(keras)
#remotes::install_github("rstudio/gt")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", "gt", "here", "stringr", prompt = TRUE)
setwd("~/GitHub/DeepLearning/Deep_Learning_with_R")
loss <- distance(style(reference_image) - style(generated_image)) +
distance(content(original_image) - content(generated_image))
library(keras)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model <- keras_model_sequential() %>%
layer_dense(units = 4, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 4, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
knitr::include_graphics("./images/network_size1.JPG")
model <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 512, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
imdb <- dataset_imdb(num_words = 10000)
#c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb
train_data <- imdb$train$x
train_labels <- imdb$train$y
test_data <- imdb$test$x
test_labels <- imdb$test$y
str(train_data[[1]])
knitr::opts_knit$set(
root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/Deep_Learning_with_R')
#remotes::install_github("rstudio/gt")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", "gt", "here", "stringr", prompt = TRUE)
setwd("~/GitHub/DeepLearning/Deep_Learning_with_R")
knitr::include_graphics("./images/DLwR_p_11.JPG")
knitr::include_graphics("./images/network_size1.JPG")
knitr::include_graphics("./images/network_size2.JPG")
knitr::include_graphics("./images/network_size3.JPG")
knitr::include_graphics("./images/network_size4.JPG")
knitr::include_graphics("./images/network_size5.JPG")
knitr::include_graphics("./images/network_size6.JPG")
imdb <- dataset_imdb(num_words = 10000)
#c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb
train_data <- imdb$train$x
train_labels <- imdb$train$y
test_data <- imdb$test$x
test_labels <- imdb$test$y
str(train_data[[1]])
head(train_labels, 10)
vectorize_sequences <- function(sequences, dimension = 10000) {
# Create an all-zero matrix of shape (len(sequences), dimension)
results <- matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
# Sets specific indices of results[i] to 1s
results[i, sequences[[i]]] <- 1
results}
# Our vectorized training data
x_train <- vectorize_sequences(train_data)
# Our vectorized test data
x_test <- vectorize_sequences(test_data)
str(x_train[1,])
# Our vectorized labels
y_train <- as.numeric(train_labels)
y_test <- as.numeric(test_labels)
knitr::include_graphics("./images/relu.png")
knitr::include_graphics("./images/Keras_Sequential.png")
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy", metrics = c("accuracy"))
val_indices <- 1:10000
x_val <- x_train[val_indices,]
partial_x_train <- x_train[-val_indices,]
y_val <- y_train[val_indices]
partial_y_train <- y_train[-val_indices]
model %>% compile(optimizer = "rmsprop", loss = "binary_crossentropy", metrics = c("accuracy"))
history <- model %>% fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 512,
validation_data = list(x_val, y_val))
str(history)
plot(history)
history_df <- as.data.frame(history)
str(history_df)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(optimizer = "rmsprop",loss = "binary_crossentropy", metrics = c("accuracy"))
model %>% fit(x_train, y_train, epochs = 4, batch_size = 512)
rm(list = ls())
knitr::opts_knit$set(
root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/DeepLearningwithR/FinalDocs/')
#remotes::install_github("rstudio/gt")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", "gt", "here", "stringr", prompt = TRUE)
setwd("~/GitHub/DeepLearning/DeepLearningwithR/FinalDocs/")
knitr::include_graphics("../images/DLwR_p_11.JPG")
../images/DLwR_p_11.JPG
knitr::include_graphics("../images/DLwR_p_11.JPG")
knitr::include_graphics("../images/figure_1_9p11.jpg")
knitr::include_graphics("../images/figure4_6_p98.jpg")
knitr::include_graphics("../images/figure4_5_p97.jpg")
knitr::include_graphics("../images/figure_4_4_p97.jpg")
knitr::include_graphics("../images/figure4_7_p99.jpg")
knitr::include_graphics("../images/figure4_9_p102.jpg.JPG")
knitr::include_graphics("../images/figure4_9_p102.jpg")
knitr::include_graphics("../images/relu.png")
knitr::include_graphics("../images/figure4_8_p101.jpg")
knitr::include_graphics("../images/figure3_5_p63.jpg")
knitr::include_graphics("../images/p66_strHistory.jpg")
knitr::opts_knit$set(
root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/DeepLearningWithR/FinalDocs/')
#remotes::install_github("rstudio/gt")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", "gt", "here", "stringr", prompt = TRUE)
setwd("~/GitHub/DeepLearning/DeepLearningWithR/FinalDocs")
imdb <- dataset_imdb(num_words = 10000)
#c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb
train_data <- imdb$train$x
train_labels <- imdb$train$y
test_data <- imdb$test$x
test_labels <- imdb$test$y
str(train_data[[1]])
head(train_labels, 10)
vectorize_sequences <- function(sequences, dimension = 10000) {
# Create an all-zero matrix of shape (len(sequences), dimension)
results <- matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
# Sets specific indices of results[i] to 1s
results[i, sequences[[i]]] <- 1
results}
# Our vectorized training data
x_train <- vectorize_sequences(train_data)
# Our vectorized test data
x_test <- vectorize_sequences(test_data)
str(x_train[1,])
# Our vectorized labels
y_train <- as.numeric(train_labels)
y_test <- as.numeric(test_labels)
knitr::include_graphics("../images/relu.png")
knitr::include_graphics("../images/Keras_Sequential.png")
knitr::opts_knit$set(
root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/Deep_Learning_with_R')
rm(list = ls())
reuters <- dataset_reuters(num_words = 10000)
summary(reuters)
summary(reuters$train)
summary(reuters$train$x[1:10])
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% reuters
length(train_data)
vectorize_sequences <- function(sequences, dimension = 10000) {
results <- matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
results[i, sequences[[i]]] <- 1
results}
x_train <- vectorize_sequences(train_data)
x_test <- vectorize_sequences(test_data)
to_one_hot <- function(labels, dimension = 46) {
results <- matrix(0, nrow = length(labels), ncol = dimension)
for (i in 1:length(labels))
results[i, labels[[i]] + 1] <- 1
results}
one_hot_train_labels <- to_one_hot(train_labels)
one_hot_test_labels <- to_one_hot(test_labels)
one_hot_train_labels <- to_categorical(train_labels)
one_hot_test_labels <- to_categorical(test_labels)
y_train <- as.numeric(train_labels)
y_test <- as.numeric(test_labels)
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy"))
val_indices <- 1:1000
x_val <- x_train[val_indices,]
partial_x_train <- x_train[-val_indices,]
y_val <- one_hot_train_labels[val_indices,]
partial_y_train = one_hot_train_labels[-val_indices,]
history <- model %>% fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 512,
validation_data = list(x_val, y_val))
plot(history)
model2 <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model2 %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy"))
history2 <- model2 %>% fit(partial_x_train, partial_y_train, epochs = 9, batch_size = 512, validation_data = list(x_val, y_val))
results2 <- model2 %>% evaluate(x_test, one_hot_test_labels)
results2
test_labels_copy <- test_labels
test_labels_copy <- sample(test_labels_copy)
length(which(test_labels == test_labels_copy)) / length(test_labels)
predictions <- model2 %>% predict(x_test)
head(predictions, 1)
dim(predictions)
sum(predictions[1,])
which.max(predictions[1,])
model3 %>% compile(optimizer = "rmsprop", loss = "sparse_categorical_crossentropy", metrics = c("accuracy"))
model3 <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 4, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model3 %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy"))
model3 %>% fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 128, validation_data = list(x_val, y_val))
plot(history)
history <- model %>% fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 512,
validation_data = list(x_val, y_val))
knitr::include_graphics("../images/listing_3_16_p73.jpg.jpg")
knitr::include_graphics("../images/listing_3_16_p73.jpg")
model2 <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model2 %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy"))
history2 <- model2 %>% fit(partial_x_train, partial_y_train, epochs = 9, batch_size = 512, validation_data = list(x_val, y_val))
results2 <- model2 %>% evaluate(x_test, one_hot_test_labels)
train_data[[1]]
train_labels[[1]]
knitr::opts_knit$set(root.dir = 'C:/Users/czwea/Documents/GitHub/DeepLearning/Deep_Learning_with_R')
rm(list = ls())
dataset <- dataset_boston_housing()
c(c(train_data, train_targets), c(test_data, test_targets)) %<-% dataset
str(train_data)
str(test_data)
str(train_targets)
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)
# Need to instantiate the same model multiple times, use a function to construct it.
build_model <- function() {
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = dim(train_data)[[2]]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(optimizer = "rmsprop", loss = "mse", metrics = c("mae"))}
k <- 4
indices <- sample(1:nrow(train_data))
folds <- cut(1:length(indices), breaks = k, labels = FALSE)
num_epochs <- 100
all_scores <- c()
for (i in 1:k) {
cat("processing fold #", i, "\n")
# Prepare the validation data: data from partition # k
val_indices <- which(folds == i, arr.ind = TRUE)
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
# Prepare the training data: data from all other partitions
partial_train_data <- train_data[-val_indices,]
partial_train_targets <- train_targets[-val_indices]
# Build the Keras model (already compiled)
model <- build_model()
# Train the model (in silent mode, verbose=0)
model %>% fit(partial_train_data, partial_train_targets,
epochs = num_epochs, batch_size = 1, verbose = 0)
# Evaluate the model on the validation data
results <- model %>% evaluate(val_data, val_targets, verbose = 0)
all_scores <- c(all_scores, results$mean_absolute_error)
}
all_scores
mean(all_scores)
# Some memory clean-up - a Keras function to avoid clutter from old models / layers.
k_clear_session()
# These lines are repeated so the code block below is self-sufficient
k <- 4
indices <- sample(1:nrow(train_data))
folds <- cut(1:length(indices), breaks = k, labels = FALSE)
num_epochs <- 500
all_mae_histories <- NULL
for (i in 1:k) {
cat("processing fold #", i, "\n")
# Prepare the validation data: data from partition # k
val_indices <- which(folds == i, arr.ind = TRUE)
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
# Prepare the training data: data from all other partitions
partial_train_data <- train_data[-val_indices,]
partial_train_targets <- train_targets[-val_indices]
# Build the Keras model (already compiled)
model <- build_model()
# Train the model (in silent mode, verbose=0)
history <- model %>% fit(
partial_train_data, partial_train_targets,
validation_data = list(val_data, val_targets),
epochs = num_epochs, batch_size = 1, verbose = 0
)
mae_history <- history$metrics$val_mean_absolute_error
all_mae_histories <- rbind(all_mae_histories, mae_history)
}
average_mae_history <- data.frame(epoch = seq(1:ncol(all_mae_histories)),
validation_mae = apply(all_mae_histories, 2, mean))
library(ggplot2)
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_line()
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_smooth()
# Get a fresh, compiled model.
model <- build_model()
# Train it on the entirety of the data.
model %>% fit(train_data, train_targets, epochs = 80, batch_size = 16, verbose = 0)
result <- model %>% evaluate(test_data, test_targets)
result
round(min(all_scores), 1)
ound(max(all_scores), 1)
round(max(all_scores), 1)
round(mean(all_scores*1000),0)
setwd("~/GitHub/MachineLearning")
#remotes::install_github("rstudio/gt")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "pasnip", "here",prompt = TRUE)
setwd("~/GitHub/MachineLearning")

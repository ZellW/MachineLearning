---
title: Manufacturing Outliers - Autoencoder w H20
author: Cliff Weaver
date: March 25, 2019
output:
  prettydoc::html_pretty:
    theme: tactile
    highlight: github
---

```{r echo=FALSE, warning=F, message=F}
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)

#H2O does not work with proxies so disable here
Sys.setenv(https_proxy="") 
Sys.setenv(http_proxy="") 
Sys.setenv(http_proxy_user="") 
Sys.setenv(https_proxy_user="") 

packages("tidyverse", "h2o", prompt = TRUE)
options(digits = 3)

h2o.init()

setwd("~/R/WIP/")
```

# Data

Data from UCI Machine Learning Library, [SECOM Data Set](https://archive.ics.uci.edu/ml/datasets/SECOM)

A complex modern semi-conductor manufacturing process is normally under consistent surveillance via the monitoring of signals/variables collected from sensors and or process measurement points. However, not all of these signals are equally valuable in a specific monitoring system. The measured signals contain a combination of useful information, irrelevant information as well as noise. It is often the case that useful information is buried in the latter two. Engineers typically have a much larger number of signals than are actually required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most relevant signals. The Process Engineers may then use these signals to determine key factors contributing to yield excursions downstream in the process. This will enable an increase in process throughput, decreased time to learning and reduce the per unit production costs. 

The dataset represents a selection of such features where each example represents a single production entity with associated measured features and the labels represent a simple pass/fail yield for in house line testing, and associated date time stamp. Where 1 corresponds to a pass and 1 corresponds to a fail and the data time stamp is for that specific test point. 

SECOM Dataset: 1567 examples 591 features, 104 fails 

- FSmethod (40 features) BER % True + % True - % 
- S2N (signal to noise) 34.5 +-2.6 57.8 +-5.3 73.1 +2.1 
- Ttest 33.7 +-2.1 59.6 +-4.7 73.0 +-1.8 
- Relief 40.1 +-2.8 48.3 +-5.9 71.6 +-3.2 
- Pearson 34.1 +-2.0 57.4 +-4.3 74.4 +-4.9 
- Ftest 33.5 +-2.2 59.1 +-4.8 73.8 +-1.8 
- Gram Schmidt 35.6 +-2.4 51.2 +-11.8 77.5 +-2.3

The data consists of 2 files the dataset file SECOM  consisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels file containing the classifications and date time stamp for each example.

As with any real life data situations this data contains null values varying in intensity depending on the individuals features. This needs to be taken into 
consideration when investigating the data either through pre-processing or within the technique applied.

The data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value.

```{r GetData}
tmpF3 <- read_delim("../data/Mfg_Outliers/secom.txt", delim = " ", col_names = FALSE, na = c("NaN"))
dim(tmpF3)
head(tmpF3)

tmpF2 <- read_csv("../data/Mfg_Outliers/secom_labels.data", col_names = FALSE, na = c("NaN"))
dim(tmpF2)
str(tmpF3)
head(tmpF2)

tmpF2 <- tmpF2 %>% separate(X1, c("Flag", "Date", "Time"), sep = " ", remove = TRUE) 
tmpF2$Date <- str_remove(tmpF2$Date, '"')
tmpF2$Time <- str_remove(tmpF2$Time, '"')


tmpF2$Date <- lubridate::dmy(tmpF2$Date)
tmpF2$Time <- lubridate::hms(tmpF2$Time)

tmpF2$Flag <- as.integer(tmpF2$Flag)

str(tmpF2)
head(tmpF2)

myData <- bind_cols(tmpF2, tmpF3)
myData <- as.data.frame(myData)
dim(myData)

rm(tmpF2, tmpF3)
```

```{r}
sum(is.na(myData[,1:3]))
sum(is.na(myData[,1:4]))
sum(is.na(myData[,1:5]))
sum(is.na(myData[,]))


# tmp <- myData %>% purrr::keep(is.numeric) %>% mutate_all(zoo::na.aggregate)
# sum(is.na(tmp[,]))

myData <- myData %>% mutate_if(is.numeric, zoo::na.aggregate)
sum(is.na(myData[,]))


# df <- tibble(x = c(1, 2, 5, 6, 7, NA), y = c(10, NA, 15, 23, 43, 43))
# mean(df$x, na.rm = T)# 4.2
# mean(df$y, na.rm = T) #26.8
# 
# df %>% mutate_if(is.numeric, zoo::na.aggregate)

```


```{r startH2O, eval=FALSE}
# Load libraries

h2o.init( nthreads = -1, max_mem_size = "5G", port = 6666 )
h2o.removeAll() ## Removes the data from the h2o cluster in preparation for our final model.
```
# Reading our data file

```{r}


library(rsample)
myData_split <- initial_split(myData, prop = 9/10)
trainData <- training(myData_split)
testData <- testing(myData_split)
# spliting all data, the fiirst 90% for training and the rest 10% for testing our model.


# Convert the training dataset to H2O format.
trainingData_h2o = as.h2o(trainData, destination_frame = "trainingData_h2o")

# Set the input variables
featureNames = colnames(trainingData_hex)

# Creating the first model version.
trainingModel = h2o.deeplearning( x = featureNames, training_frame = trainingData_hex
                                  , model_id = "Station1DeepLearningModel"
                                  , activation = "Tanh"
                                  , autoencoder = TRUE
                                  #, reproducible = FALSE
                                  , reproducible = TRUE
                                  , l1 = 1e-5
                                  , ignore_const_cols = FALSE
                                  , seed = 1234
                                  , hidden = c( 400, 200, 400 ), epochs = 50 )


# Getting the anomaly with training data to set the min MSE( Mean Squared Error )
# value before setting a record as anomally
trainMSE = as.data.frame( h2o.anomaly( trainingModel
                                       , trainingData_hex
                                       , per_feature = FALSE ) )

# Check the first 30 descendent sorted trainMSE records to see our outliers
head( sort( trainMSE$Reconstruction.MSE , decreasing = TRUE ), 30)
```


# Ploting the errors of reconstructing our training data, to have a graphical view
# of our data reconstruction errors
plot( sort( trainMSE$Reconstruction.MSE ), main = 'Reconstruction Error', ylab = "MSE Value." )

# Seeing the chart and the first 30 decresing sorted MSE records, we can decide .01 
# as our min MSE before setting a record as anomally, because we see Just a few 
# records with two decimals greater than zero and we can set those as outliers.
# This value is something you must decide for your data.

# Updating trainingData data set with reconstruction error < .01
trainingDataNew = trainingData[ trainMSE$Reconstruction.MSE < .01, ]

h2o.removeAll() ## Remove the data from the h2o cluster in preparation for our final model.

# Convert our new training data frame to H2O format.
trainingDataNew_hex = as.h2o( trainingDataNew, destination_frame = "train_hex" )

# Creating the final model.
trainingModelNew = h2o.deeplearning( x = featureNames, training_frame = trainingDataNew_hex
                                     , model_id = "Station1DeepLearningModel"
                                     , activation = "Tanh"
                                     , autoencoder = TRUE
                                     #, reproducible = FALSE
                                     , reproducible = TRUE
                                     , l1 = 1e-5
                                     , ignore_const_cols = FALSE
                                     , seed = 1234
                                     , hidden = c( 400, 200, 400 ), epochs = 50 )




#######################################
# Check our testing data for anomalies.
#######################################

# Convert our testing data frame to H2O format.
testingDataH2O = as.h2o( testingData, destination_frame = "test_hex" )

# Getting anomalies found in testing data.
testMSE = as.data.frame( h2o.anomaly( trainingModelNew
                                      , testingDataH2O
                                      , per_feature = FALSE ) )

# Binding our data.
testingData = cbind( MSE = testMSE$Reconstruction.MSE , testingData )

# Filter testing data using the MSE value set as minimum.
anomalies = testingData[ testingData$MSE >= .01,  ]

# When anomalies detected, send a notice to maintenance area.
if( dim(anomalies)[1] > 0 ){
  cat( "Anomalies detected in the sample data, station needs maintenance." )
}

# References

- https://www.r-bloggers.com/using-r-and-h2o-to-identify-product-anomalies-during-the-manufacturing-process/

---
title: 'DrWhy auditor Residuals Package'
output:
  rmdformats::readthedown:
    highlight: pygments
    code_folding: show
  df_print: paged
---
<style type="text/css">
p{ /* Normal  */
   font-size: 14px;
   line-height: 18px;}
body{ /* Normal  */
   font-size: 14px;}
td {  /* Table  */
   font-size: 12px;}
h1 { /* Header 1 */
 font-size: 26px;
 color: #4294ce;}
h2 { /* Header 2 */
 font-size: 22px;}
h3 { /* Header 3 */
 font-size: 18px;}
code.r{ /* Code block */
  font-size: 12px;}
pre { /* Code block */
  font-size: 12px}
#table-of-contents h2 {
  background-color: #4294ce;}
#table-of-contents{
  background: #688FAD;}
#nav-top span.glyphicon{
  color: #4294ce;}
#postamble{
  background: #4294ce;
  border-top: ;}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r loadLibs, echo=FALSE, warning=FALSE, message=FALSE}
setwd("~/R/SER/")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("dplyr", "ggplot2", "ggResidpanel", "DALEX", "auditor", prompt = F)
set.seed(123)
options(digits = 3)
```

# Introduction

Describe `auditor` for visual auditing of residuals of machine learning models. A residual is the difference between the observed value and the value predicted by a model. `auditor` provides methods for verification and validation of models. It helps in finding answers to questions that may be crucial in deeper analyses of models.

- Does the model fit the data? Is it not missing any information?
- Which model has better performance?
- How similar are models?

Residual plots are not extendable to other models. At the same time, many algorithms, such as random forests or neural networks are often treated as black boxes and there are few or no methods for errors analysis. `auditor` comes as a solution to the problems. It is a toolbox with model-agnostic validation plots, which means that they can be used regardless of the expected distribution of residuals. `auditor` provides flexible and consistent grammar for validation of any model class.

# Traditional Residuals

A residual plot is typically used to find problems with regression. Some data sets are not good candidates for regression, including:

- Heteroscedastic data (points at widely varying distances from the line).
- Data that is non-linearly associated.
- Data sets with outliers.

Linear models have a very simple structure and do not require high computational power, therefore, there are many tools that validate different aspects of these models. `plot()` from the `stats` generates six types of diagnostic plots for “lm” and “glm” objects.

```{r}
eruption.lm = lm(eruptions ~ waiting, data=faithful)
resid_panel(eruption.lm)
```

4 key assumptions

1. Independence of observations
2. Linearity between the response variable and the predictor variables
3. Constant variance of the residuals
4. Normality of the residuals

The first assumption can only be checked by considering the study design. Typically this is accounted for by including a random effects. The other assumptions can be checked by looking at residual diagnostic plots. These plots can be easily created by applying the function `resid_panel` from `ggResidpanel` to the model.  [See viginette]. https://cran.r-project.org/web/packages/ggResidpanel/vignettes/introduction.html By default, a panel with four plots is created. The default panel includes the following four plots.

__Residual Plot__ (upper left): This is a plot of the residuals versus predictive values from the model to assess the linearity and constant variance assumptions. The curving trend seen in the penguin_model plot suggests a violation of the linearity assumption, and there appears to be a violation of the constant variance assumption as well since the variance of the residuals is getting larger as the predicted values increase.
__Normal Quantile Plot__ (upper right): Also known as a qq-plot, this plot allows us to assess the normality assumption. There appears to be a deviation from normality in the upper end of the residuals from the penguin_model, but this is not as much of a concern as linearity and constant variance issues.
__Histogram__ (lower right): This is a histogram of the residuals with a overlaid normal density curve with mean and standard deviation computed from the residuals. It provides an additional way to check the normality assumption. This plot makes it clear that there is a slight right skew in the residuals from the penguin_model.
__Index Plot__ (lower left): This is a plot of the residuals versus the observation numbers. It can help to find patterns related to the way that the data has been ordered, which may provide insights into additional trends in the data that have not been accounted for in the model. There is no obvious trend in the penguin_model index plot.

# Data

To illustrate application of `auditor`, use dataset `dragons` available in `DALEX`. The dataset contains characteristics of fictional creatures (dragons), like year of birth, height, weight, etc (see below). The goal is to predict the length of life of dragons (a regression problem).

```{r}
rm(list = ls())
dragons <- DALEX2::dragons
head(dragons)
```

# Models

Need models to compare. Select linear regression and random forest because of their different structures. Linear regression model linear relationships between target response and independent variables, while random forest should be able to capture also non-linear relationships between variables.

```{r}
# Linear regression
lm_model <- lm(life_length ~ ., data = dragons)

# Random forest
library(randomForest)
set.seed(59)
rf_model <- randomForest(life_length ~ ., data = dragons)
```

## Preparation for Residual Analysis

Analysis begins with creation of an explainer object with explain function from `DALEX.` Explainer wraps a model with its meta-data, such as dataset that was used for training or observed response.

```{r}
lm_exp <- DALEX::explain(lm_model, label = "lm", data = dragons, y = dragons$life_length)
rf_exp <- DALEX::explain(rf_model, label = "rf", data = dragons, y = dragons$life_length)
 
```

Next step requires creation of `model_residual` objects of each explainer. From this step on, only `auditor` functions are used.

```{r}
lm_mr <- model_residual(lm_exp)
rf_mr <- model_residual(rf_exp)
```

## Plots

### Observed vs Predicted

First plot compares predicted versus observed values. The red line corresponds to the $y = x$ function. The patterns for both models are non-random around the diagonal line. The points corresponding to a random forest (darker dots) show the tendency to underprediction for large values of observed response.

Points for linear model (lighter dots) are located more or less around diagonal line which means that this model predicts quite well.

```{r}
plot(rf_mr, lm_mr, type = "prediction", abline = TRUE)

# alternatives:
# plot_prediction(rf_mr, lm_mr, abline = TRUE)
# plot_prediction(rf_mr, lm_mr, variable = "life_length")
```

`plot_prediction` presents observed values on the x-axis. However, on the x-axis there may be values of any model variable or observations ordered by index (variable = NULL).

```{r}
p2 <- plot(rf_mr, lm_mr, variable = "height", type = "prediction")
p3 <- plot(rf_mr, lm_mr, variable = "scars", type = "prediction")
cowplot::plot_grid(p2, p3)
```

On the plots above, there is no relationship for variable `height` and predicted values while for increasing number of `scars` model predictions also increase of `life length. This means that that model captured monotonic relationship between number of `scars` and `length of life` of dragon.`

### Residuals vs Observed Fitted or Variable Values

`plot_residual()` shows residuals versus observed values. This plot is _used to detect dependence of errors, unequal error variances, and outliers_. For appropriate model, residuals should not show any functional dependency. Expected mean value should be equal to 0, regardless of \(\hat{y}\) values, so any structured arrangement of points suggests a problem with the model. It is worth looking at the observations that clearly differ from the others. If points on the plot are not randomly dispersed around the horizontal axis, it may be presumed that model is not appropriate for the data.

```{r}
plot(lm_mr, rf_mr, type = "residual")

# alternative:
# plot_residual(lm_mr, rf_mr)
```

Values (residuals) may also be ordered by target variable, fitted values, any other variable or may be presented unordered.

```{r}
p3 <- plot(rf_mr, lm_mr, type = "residual", variable = "_y_hat_")
p4 <- plot(rf_mr, lm_mr, type = "residual", variable = "scars")
cowplot::plot_grid(p3, p4)

# alternative:
# plot_residual(rf_mr, lm_mr, variable = "_y_hat_")
# plot_residual(rf_mr, lm_mr, variable = "scars")
```
In all the examples above, the linear model is better fitted for the data than random forest, because for the latter one greater values of selected variables residuals are also geater. Additionaly, identify most outlying observations:

```{r}
plot_residual(rf_mr, variable = "_y_hat_", nlabel = 10)
```

### Density of Residuals

`plot_residual_density()` detects the incorrect behavior of residuals. The funcion returns plot with estimated densities of residuals. Their values are displayed as marks along the x axis. For some models, the expected shape of density could be derived from the model assumptions. For example, simple linear model residuals should be normally distributed. However, even if the model does not have an assumption about the distribution of residuals residual density plot may be informative. If most of the residuals are not concentrated around zero, it is likely that the model predictions are biased.

```{r}
plot(rf_mr, lm_mr, type = "residual_density")

# alternative
# plot_residual_density(rf_mr, lm_mr)
```

Resuduals may be also divided by values of a choosen variable (median of a numeric variable or levels of a factor).

```{r}
plot_residual_density(rf_mr, lm_mr, variable = "colour")
```

### Boxplot of Residuals

`plotResidualBoxplot()` shows the distribution of the absolute values of residuals. Boxplot usually presents following values:
box width which corresponds to the second and third quartile, vertical line which reflects median, the whiskers which extend to the smallest and largest values, no further than 1.5 of interquartile.

`auditor` adds another component to the boxplot which is the root mean square error (RMSE) measure, shown as X. For the appropriate model, box should lay near zero. A large spread of values indicates problems with a model. Comparing the two models, one can see that random forest model is much more spreaded (worse) than linear one.

```{r}
plot(lm_mr, rf_mr, type = "residual_boxplot")

# alternative
# plot_residual_boxplot(lm_mr, rf_mr)
```

There is much more to learn in `auditor.` 

# Source

https://feelml.com/post/2019-09-10-auditor/

